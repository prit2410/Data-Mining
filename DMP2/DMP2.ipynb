{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Load the main dataset\n",
        "data = pd.read_csv(\"/content/nba_stats.csv\")  # Ensure this path is correct for your setup\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(\"Pos\", axis=1)  # Features\n",
        "y = data[\"Pos\"]               # Target variable\n",
        "\n",
        "# Convert categorical columns to numeric (e.g., \"Tm\" for team) using one-hot encoding\n",
        "X = pd.get_dummies(X, columns=[\"Tm\"])\n",
        "\n",
        "# Feature Selection: Select the top 20 features based on ANOVA F-value\n",
        "selector = SelectKBest(f_classif, k=20)\n",
        "X = selector.fit_transform(X, y)\n",
        "\n",
        "# Standardize the feature data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define a parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50, 30), (100,), (50, 30, 10)],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate_init': [0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# Initialize the MLPClassifier and GridSearchCV\n",
        "# Early stopping was causing issues, so it has been turned off.\n",
        "mlp = MLPClassifier(max_iter=1000, random_state=0, early_stopping=False, validation_fraction=0.1)\n",
        "grid_search = GridSearchCV(mlp, param_grid, cv=5, n_jobs=-1, verbose=0)\n",
        "\n",
        "# Fit the model using grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_mlp = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions with the best model\n",
        "train_predictions = best_mlp.predict(X_train)\n",
        "test_predictions = best_mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model on training and test sets\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "train_conf_matrix = confusion_matrix(y_train, train_predictions)\n",
        "test_conf_matrix = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy:.2f}\")\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(train_conf_matrix)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(test_conf_matrix)\n",
        "\n",
        "# Cross-validation using the best model\n",
        "cv_scores = cross_val_score(best_mlp, X, y, cv=10)\n",
        "print(\"\\nCross-validation Scores:\", cv_scores)\n",
        "print(\"Average Cross-validation Accuracy:\", np.mean(cv_scores))\n",
        "\n",
        "# Load the dummy test set\n",
        "dummy_test = pd.read_csv(\"/content/dummy_test.csv\")  # Ensure this path is correct for your setup\n",
        "y_dummy = dummy_test[\"Pos\"]  # Extract target variable from dummy test set\n",
        "\n",
        "# Preprocess the dummy test data\n",
        "dummy_test = dummy_test.drop(\"Pos\", axis=1)  # Drop target column from dummy test set\n",
        "dummy_test = pd.get_dummies(dummy_test, columns=[\"Tm\"])  # Ensure same encoding as training data\n",
        "dummy_test = selector.transform(dummy_test)  # Select same features as training data\n",
        "dummy_test = scaler.transform(dummy_test)    # Apply scaling\n",
        "\n",
        "# Evaluate the model on the dummy test set\n",
        "dummy_predictions = best_mlp.predict(dummy_test)\n",
        "dummy_accuracy = accuracy_score(y_dummy, dummy_predictions)\n",
        "dummy_conf_matrix = confusion_matrix(y_dummy, dummy_predictions)\n",
        "\n",
        "print(f\"\\nDummy Test Accuracy: {dummy_accuracy:.2f}\")\n",
        "print(\"Dummy Test Confusion Matrix:\")\n",
        "print(dummy_conf_matrix)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y60FOJXzAyp_",
        "outputId": "0b07c973-77df-4f53-b238-af31eb3d2079"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Accuracy: 0.94\n",
            "Training Confusion Matrix:\n",
            "[[127   1   0   1   0]\n",
            " [  2 132   2   2   0]\n",
            " [  0   1 130   2   1]\n",
            " [  1   5   1 114  10]\n",
            " [  0   1   2   7 142]]\n",
            "\n",
            "Test Accuracy: 0.60\n",
            "Test Confusion Matrix:\n",
            "[[21  8  0  0  0]\n",
            " [ 8 15  3 13  2]\n",
            " [ 0  0 28  2  2]\n",
            " [ 1  3  2 14  9]\n",
            " [ 0  1  8  6 25]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation Scores: [0.60465116 0.56976744 0.55813953 0.56976744 0.58139535 0.51764706\n",
            " 0.56470588 0.62352941 0.44705882 0.52941176]\n",
            "Average Cross-validation Accuracy: 0.5566073871409029\n",
            "\n",
            "Dummy Test Accuracy: 0.80\n",
            "Dummy Test Confusion Matrix:\n",
            "[[15  1  0  0  0]\n",
            " [ 1 16  1  2  0]\n",
            " [ 0  0 16  1  1]\n",
            " [ 1  2  1 17  6]\n",
            " [ 0  0  1  3 18]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}